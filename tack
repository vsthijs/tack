#!/usr/bin/env python3

"""
toplevel statements
-------------------

function definition:
```
func <name> <arg0> <arg1> <argn> -> <ret> do
    <expressions>
end
```

function declaration:
```
func <name> <arg0> <arg1> <argn> -> <ret> extern
```

constant definition:
```
const <name> <value>
```
TODO: support small compile-time expressions in const value

include statement:
```
include "<file>"
```

typedef statement:
```
typedef <name> <type>
```
TODO: lex, parse, compile

extern variable/symbol:
```
extern <name> <type>
```
TODO: lex, parse, compile

static memory:
```
static <name> <type> <value>
```
TODO: lex, parse, compile

expressions
-----------

- 0: pushes zero to the stack.
- +, -, *, /: apply the corresponding math operations to the top two numbers
              on the stack.
- drop, over, swap, rot, dup: just like forth.
- int, uint, bool, ptr: convert to corresponding type.
- int!, uint!, bool!, ptr!: write to a memory address.
    - TODO: lex, parse, compile
- int@, uint@, bool@, ptr@: read from a memory address.
    - TODO: lex, parse, compile

- if <expressions> end
- if <expressions> else <expressions> end

- loop <expressions> end: pop condition from stack, and continue if not zero.
    - TODO: lex, parse, compile
"""

# TODO: test intrinsics

# TODO: verify main function

# TODO: add more examples

from enum import Enum, auto
from dataclasses import dataclass
import copy
from typing import TextIO, Any
import sys
import subprocess
import tempfile
import os

DEBUG = True
VERBOSE = False


def assert_ex(cond: bool, exception: Exception):
    if not cond:
        raise exception


def eprint(*values: str, sep: str = ' ', end='\n', **kwargs):
    return print(*values, sep=sep, end=end, file=sys.stderr, **kwargs)


def verbose(*values: str, sep: str = ' ', end='\n', **kwargs):
    if VERBOSE:
        print(*values, sep=sep, end=end, **kwargs)


def get_stdlib() -> str:
    basepath = os.path.dirname(__file__)
    if os.path.exists(path := os.path.join(basepath, 'libtack.a')):
        return path
    elif os.path.exists(path := os.path.join(basepath, 'lib', 'libtack.a')):
        return path
    eprint(f'{sys.argv[0]}: error: could not find libtack.a')
    exit(1)


def get_include_path() -> list[str]:
    pathlist = ['/usr/include']
    basepath = os.path.dirname(__file__)
    if os.path.exists(path := os.path.join(basepath, 'lib', 'include')):
        pathlist.append(path)
    else:
        print(f"warning: could not find stdlib include directory at {path}")
    return pathlist


class ParseError(Exception):
    def __init__(self, *args: Any) -> None:
        super().__init__(' '.join(str(a) for a in args))


TYPES: list[str] = ['int', 'bool', 'long', 'ptr']


class TokenType(Enum):
    Identifier = auto()
    Number = auto()
    String = auto()

    Arrow = auto()
    Minus = auto()
    Plus = auto()
    Star = auto()
    Slash = auto()
    Lt = auto()
    Gt = auto()
    Lte = auto()
    Gte = auto()
    Eq = auto()
    Neq = auto()
    BwAnd = auto()
    BwOr = auto()
    Lsh = auto()
    Rsh = auto()

    Do = auto()
    End = auto()
    Func = auto()
    Const = auto()
    If = auto()
    Else = auto()
    Extern = auto()
    Include = auto()

    Not = auto()
    Neg = auto()
    Dup = auto()
    Drop = auto()
    Swap = auto()
    Rot = auto()
    Over = auto()

    Int = auto()
    Bool = auto()
    Ptr = auto()
    Long = auto()

    Str = auto()  # type alias for ptr


KEYWORDS: dict[str, TokenType] = {
    'do': TokenType.Do,
    'end': TokenType.End,
    'func': TokenType.Func,
    'const': TokenType.Const,
    'if': TokenType.If,
    'else': TokenType.Else,
    'extern': TokenType.Extern,
    'include': TokenType.Include,
    'not': TokenType.Not,
    'neg': TokenType.Neg,
    'dup': TokenType.Dup,
    'drop': TokenType.Drop,
    'swap': TokenType.Swap,
    'rot': TokenType.Rot,
    'over': TokenType.Over,
    'int': TokenType.Int,
    'bool': TokenType.Bool,
    'ptr': TokenType.Ptr,
    'long': TokenType.Long,
    'str': TokenType.Str
}


class Intrinsic(Enum):
    Add = auto()
    Sub = auto()
    Mul = auto()
    Div = auto()
    Lt = auto()
    Gt = auto()
    Lte = auto()
    Gte = auto()
    Eq = auto()
    Neq = auto()
    BwAnd = auto()
    BwOr = auto()
    Lsh = auto()
    Rsh = auto()
    Not = auto()
    Neg = auto()
    Dup = auto()
    Drop = auto()
    Swap = auto()
    Rot = auto()
    Over = auto()

    Int = auto()
    Bool = auto()
    Ptr = auto()
    Long = auto()
    Str = auto()


def intrinsic2str(i: Intrinsic) -> str:
    return {
        Intrinsic.Add: '+',
        Intrinsic.Sub: '-',
        Intrinsic.Mul: '*',
        Intrinsic.Div: '/',
        Intrinsic.Lt: '<',
        Intrinsic.Gt: '>',
        Intrinsic.Lte: '<=',
        Intrinsic.Gte: '>=',
        Intrinsic.Eq: '=',
        Intrinsic.Neq: '!=',
        Intrinsic.BwAnd: '&',
        Intrinsic.BwOr: '|',
        Intrinsic.Lsh: '<<',
        Intrinsic.Rsh: '>>',
        Intrinsic.Not: 'not',
        Intrinsic.Neg: 'neg',
        Intrinsic.Dup: 'dup',
        Intrinsic.Drop: 'drop',
        Intrinsic.Swap: 'swap',
        Intrinsic.Rot: 'rot',
        Intrinsic.Over: 'over',
        Intrinsic.Int: 'int',
        Intrinsic.Bool: 'bool',
        Intrinsic.Ptr: 'ptr',
        Intrinsic.Long: 'long',
        Intrinsic.Str: 'str',
    }[i]


INTRINSICS: dict[TokenType, tuple[Intrinsic, list[str], list[str]]] = {
    TokenType.Plus: (Intrinsic.Add, ['int', 'int'], ['int']),
    TokenType.Minus: (Intrinsic.Sub, ['int', 'int'], ['int']),
    TokenType.Star: (Intrinsic.Mul, ['int', 'int'], ['int']),
    TokenType.Slash: (Intrinsic.Div, ['int', 'int'], ['int']),
    TokenType.Lt: (Intrinsic.Lt, ['int', 'int'], ['bool']),
    TokenType.Gt: (Intrinsic.Gt, ['int', 'int'], ['bool']),
    TokenType.Lte: (Intrinsic.Lte, ['int', 'int'], ['bool']),
    TokenType.Gte: (Intrinsic.Gte, ['int', 'int'], ['bool']),
    TokenType.Eq: (Intrinsic.Eq, ['int', 'int'], ['bool']),
    TokenType.Neq: (Intrinsic.Neq, ['int', 'int'], ['bool']),
    TokenType.BwAnd: (Intrinsic.BwAnd, ['int', 'int'], ['int']),
    TokenType.BwOr: (Intrinsic.BwOr, ['int', 'int'], ['int']),
    TokenType.Lsh: (Intrinsic.Lsh, ['int', 'int'], ['int']),
    TokenType.Rsh: (Intrinsic.Rsh, ['int', 'int'], ['int']),
    TokenType.Not: (Intrinsic.Not, ['a'], ['a']),
    TokenType.Neg: (Intrinsic.Neg, ['int'], ['int']),
    TokenType.Dup: (Intrinsic.Dup, ['a'], ['a', 'a']),
    TokenType.Drop: (Intrinsic.Drop, ['a'], []),
    TokenType.Swap: (Intrinsic.Swap, ['a', 'b'], ['b', 'a']),
    TokenType.Rot: (Intrinsic.Rot, ['a', 'b', 'c'], ['b', 'c', 'a']),
    TokenType.Over: (Intrinsic.Over, ['a', 'b'], ['a', 'b', 'a']),
    TokenType.Int: (Intrinsic.Int, ['a'], ['int']),
    TokenType.Bool: (Intrinsic.Bool, ['a'], ['bool']),
    TokenType.Ptr: (Intrinsic.Ptr, ['a'], ['ptr']),
    TokenType.Long: (Intrinsic.Long, ['a'], ['long']),
    TokenType.Str: (Intrinsic.Str, ['a'], ['ptr']),
}

TypeStack = list[str]


def match_type(expected: str, found: str) -> bool:
    return expected == found


def validate_stack(stack: TypeStack, args: TypeStack, rets: TypeStack):
    """
    applies a mutation to a type stack after checking types.
    """
    assert_ex(len(stack) >= len(args), TypeError(
        'not enough values on the stack.\n|- expected: ' +
        ' '.join(args)+'\n`- got: ' + ' '.join(stack)
    ))
    oldstack = stack.copy()
    generics: dict[str, str] = {}
    for arg in args:
        actual = stack.pop()
        if arg not in TYPES:
            if arg not in generics:
                verbose(f'pop {actual} ({arg})')
                generics[arg] = actual
            else:
                verbose(f'pop {actual} ({arg})')
                assert_ex(generics[arg] == actual,
                          TypeError('mismatching types on the stack.\n|- got: ' +
                                    ' '.join(oldstack[-len(args):]) +
                                    '\n`- but expected: '
                                    + ' '.join(args)))
        else:
            verbose(f'pop {actual}')
            assert_ex(arg == actual,
                      TypeError('mismatching types on the stack.\n|- got: ' +
                                ' '.join(oldstack[-len(args):]) +
                                '\n`- but expected: ' + ' '.join(args)))
    for ret in reversed(rets):
        if ret in TYPES:
            verbose(f'push {ret}')
            stack.append(ret)
        else:
            verbose(f'push {generics[ret]} ({ret})')
            stack.append(generics[ret])


@dataclass
class Position:
    line: int
    column: int
    file: str | None = None

    def __repr__(self):
        return (('' if self.file is None else self.file+':')
                + str(self.line+1)
                + ':'+str(self.column+1)+':')


@dataclass
class Token:
    ttype: TokenType
    pos: Position
    source: str


class Lexer:
    def __init__(self, source: TextIO):
        self.stream = source
        self.putback: str | None = None
        self.lookahead: list[Token] = []
        self.position = Position(0, 0)
        if hasattr(self.stream, 'name'):
            self.position.file = self.stream.name

    def __del__(self):
        self.stream.close()

    def peek_char(self) -> str:
        self.putback = self.get_char()
        return self.putback

    def consume_char(self) -> str | None:
        c = self.get_char()
        self.position.column += 1
        if c == '\n':
            self.position.line += 1
            self.position.column = 0
        return c

    def get_char(self) -> str | None:
        if self.putback:
            c = self.putback
            self.putback = None
        else:
            c = self.stream.read(1)
        if len(c) < 1:
            return None
        return c

    def add_lookahead(self) -> bool:
        while True:
            if (ch := self.peek_char()) and ch.isspace():
                self.consume_char()
            elif (ch := self.peek_char()) and ch == '#':
                while self.peek_char() != '\n':
                    self.consume_char()
                self.consume_char()  # also skip the newline
            else:
                break

        pos = copy.copy(self.position)
        source = ''
        if (ch := self.peek_char()) and (ch.isalpha() or ch in '_'):
            while (ch := self.peek_char()) and (ch.isalnum() or ch in '_.'):
                source += self.consume_char()
            self.lookahead.append(Token(
                TokenType.Identifier if source not in KEYWORDS else KEYWORDS[source],
                pos, source))

        elif (ch := self.peek_char()) and ch.isdigit():
            while (ch := self.peek_char()) and ch.isdigit():
                source += self.consume_char()
            self.lookahead.append(Token(TokenType.Number, pos, source))

        elif self.peek_char() == '"':
            source += self.consume_char()
            while self.peek_char() != '"':
                source += self.consume_char()
            source += (ch := self.consume_char())
            assert_ex(ch == '"', ParseError(
                pos, 'expected string termination'))
            self.lookahead.append(Token(TokenType.String, pos, source))

        else:
            match ch := self.consume_char():
                case '-':
                    if self.peek_char() == '>':
                        self.consume_char()
                        self.lookahead.append(
                            Token(TokenType.Arrow, pos, '->'))
                    else:
                        self.lookahead.append(Token(TokenType.Minus, pos, '-'))

                case '+' | '*' | '/' | '=' | '&' | '|':
                    self.lookahead.append(Token({
                        '+': TokenType.Plus,
                        '*': TokenType.Star,
                        '/': TokenType.Slash,
                        '=': TokenType.Eq,
                        '&': TokenType.BwAnd,
                        '|': TokenType.BwOr,
                    }[ch], pos, ch))

                case '<' | '>' | '!':
                    if self.peek_char() == '=':
                        self.consume_char()
                        self.lookahead.append(
                            Token({
                                '<': TokenType.Lte,
                                '>': TokenType.Gte,
                                '!': TokenType.Neq
                            }[ch], pos, ch+'='))
                    elif self.peek_char() == ch and ch in '<>':
                        self.consume_char()
                        self.lookahead.append(
                            Token({'<': TokenType.Lsh, '>': TokenType.Rsh}[
                                  ch], pos, ch+ch)
                        )
                    else:
                        self.lookahead.append(Token({
                            '<': TokenType.Lt,
                            '>': TokenType.Gt
                        }[ch], pos, ch))

                case None:
                    return False

                case _:
                    assert_ex(False, ParseError(
                        pos, f'unexpected character: \'{ch}\' ({ord(ch)})'))
        return True

    def peek(self, offset: int = 0) -> Token:
        run = True
        while len(self.lookahead) <= offset and run:
            run = self.add_lookahead()
        return self.lookahead[offset]

    def next(self) -> Token:
        if len(self.lookahead) < 1:
            self.add_lookahead()
        return self.lookahead.pop(0)


class AstNode:
    source: str


class Expression:
    pass


class Op:
    pos: Position
    source: str


class IntrinsicOp(Op):
    def __init__(self, intrinsic: Intrinsic, pos: Position) -> None:
        self.intrinsic, self.pos = intrinsic, pos
        self.source = intrinsic2str(self.intrinsic)


class PushInt(Op):
    def __init__(self, value: int, pos: Position, source: str):
        self.value, self.pos, self.source = value, pos, source


class PushStr(Op):
    def __init__(self, value: str, pos: Position, source: str):
        self.value, self.pos, self.source = value, pos, source


class FunctionCall(Op):
    def __init__(self, name: str, signature: tuple[TypeStack, TypeStack], pos: Position):
        self.name, self.signature, self.source, self.pos = name, signature, name, pos


class ConstDef(AstNode):
    def __init__(self, name: str, value: int, pos: Position):
        self.name, self.value, self.pos = name, value, pos
        self.source = f'const {self.name.strip()} {str(self.value)}\n'


class FuncDef(AstNode):
    def __init__(self, name: str, signature: tuple[TypeStack, TypeStack], body: list[Op], pos: Position, extern: bool = False) -> None:
        self.name, self.signature, self.body, self.pos, self.extern = name, signature, body, pos, extern
        self.source = f'func {name.strip()} ' + ' '.join(self.signature[0])+' -> ' + ' '.join(
            self.signature[1])+' do\n\t' + ' '.join(a.source for a in self.body) + '\nend'


class Conditional(Op):
    def __init__(self, if_true: list[Op], if_false: list[Op], pos: Position):
        self.if_true, self.if_false, self.pos = if_true, if_false, pos
        self.source = 'if ' + ' '.join(a.source for a in self.if_true)
        if len(if_false):
            self.source += ' else ' + ' '.join(a.source for a in self.if_false)
        self.source += ' end'


class Parser:
    def __init__(self, lexer: Lexer, include_path: list[str] = [],
                 include_history: list[str] = [],
                 included_from: str | None = None) -> None:
        self.lexer = lexer
        self.include_history = include_history
        self.include_path = include_path
        self.other_parser: Parser | None = None
        self.constants: dict[str, int] = {}
        self.funcs: dict[str, tuple[TypeStack, TypeStack]] = {}
        self.parent = included_from

    def next_const_expr(self) -> int:
        stack = []
        pos = self.lexer.peek().pos
        source = ''
        try:
            while True:
                match self.lexer.peek().ttype:
                    case TokenType.Number:
                        stack.append(int((tok := self.lexer.next()).source))
                        source += ' ' + tok.source

                    case TokenType.Plus:
                        source += ' ' + self.lexer.next().source
                        b = stack.pop()
                        a = stack.pop()
                        stack.append(a + b)

                    case TokenType.Minus:
                        source += ' ' + self.lexer.next().source
                        b = stack.pop()
                        a = stack.pop()
                        stack.append(a - b)

                    case TokenType.Star:
                        source += ' ' + self.lexer.next().source
                        b = stack.pop()
                        a = stack.pop()
                        stack.append(a * b)

                    case TokenType.Slash:
                        source += ' ' + self.lexer.next().source
                        b = stack.pop()
                        a = stack.pop()
                        stack.append(a // b)

                    case _:
                        assert_ex(len(stack) == 1,
                                  ParseError(pos, 'expected expression with one result'))
                        return stack[0]
        except IndexError:
            assert_ex(len(stack) == 1,
                      ParseError(pos, 'expected expression with one result'))
            return stack[0]

    def next_const(self) -> ConstDef:
        assert (const := self.lexer.next()).ttype == TokenType.Const
        identifier = self.lexer.next()
        assert_ex(identifier.ttype == TokenType.Identifier,
                  ParseError(const.pos, 'expected identifier to assign const value to.'))
        value = self.next_const_expr()
        return ConstDef(identifier.source, value, const.pos)

    def parse_op(self, tok: Token, stack: TypeStack) -> Op:
        if tok.ttype in INTRINSICS:
            intrinsic, args, rets = INTRINSICS[tok.ttype]
            try:
                verbose(f'intrinsic {intrinsic2str(intrinsic)}')
                validate_stack(stack, args, rets)
            except TypeError as e:
                raise ParseError(tok.pos, tok.source, str(e))
            return IntrinsicOp(intrinsic, tok.pos)
        elif (tok.ttype == TokenType.Identifier
              and tok.source in self.constants):
            validate_stack(stack, [], ['int'])
            return PushInt(self.constants[tok.source], tok.pos, tok.source)
        elif tok.ttype == TokenType.Identifier and tok.source in self.funcs:
            args, rets = self.funcs[tok.source]
            validate_stack(stack, args, rets)
            return FunctionCall(tok.source, (args, rets), tok.pos)
        elif tok.ttype == TokenType.Identifier:
            raise ParseError(tok.pos, f'undefined name \'{tok.source}\'')
        elif tok.ttype == TokenType.Number:
            validate_stack(stack, [], ['int'])
            return PushInt(int(tok.source), tok.pos, tok.source)
        elif tok.ttype == TokenType.If:
            validate_stack(stack, ['bool'], [])
            if_true: list[Op] = []
            if_true_stack = stack.copy()
            while self.lexer.peek().ttype not in [TokenType.End,
                                                  TokenType.Else]:
                if_true.append(self.parse_op(self.lexer.next(), if_true_stack))
            if (end := self.lexer.next()).ttype == TokenType.End:
                assert_ex(if_true_stack == stack, ParseError(
                    end.pos, 'stack has been changed after if block'))
                return Conditional(if_true, [], tok.pos)
            if_false: list[Op] = []
            if_false_stack = stack.copy()
            while self.lexer.peek().ttype != TokenType.End:
                if_false.append(self.parse_op(
                    self.lexer.next(), if_false_stack))
            assert_ex((end := self.lexer.next()).ttype == TokenType.End,
                      ParseError(end.pos,
                                 'if-else construct was not ended with end'))
            assert_ex(if_false_stack == if_true_stack, ParseError(
                end.pos, 'if-else construct has two different stack results.'))
            return Conditional(if_true, if_false, tok.pos)
        elif tok.ttype == TokenType.String:
            validate_stack(stack, [], ['ptr'])
            return PushStr(tok.source.removeprefix('"').removesuffix('"'),
                           tok.pos, tok.source)
        else:
            assert False, "unexpected token: "+str(tok)

    def next_func(self) -> FuncDef:
        assert (func := self.lexer.next()).ttype == TokenType.Func
        identifier = self.lexer.next()
        assert_ex(identifier.ttype == TokenType.Identifier,
                  ParseError(func.pos,
                             'expected identifier to assign function to'))
        args: list[str] = []
        rets: list[str] = []
        while (tok := self.lexer.next()).ttype != TokenType.Arrow:
            args.append(tok.source)
        assert_ex(tok.ttype == TokenType.Arrow, ParseError(
            tok.pos,
            'function arguments and returns should be seperated by \'->\''))
        while (tok := self.lexer.next()).ttype not in [TokenType.Do,
                                                       TokenType.Extern]:
            rets.append(tok.source)

        if tok.ttype == TokenType.Extern:
            return FuncDef(identifier.source, (args, rets), [], func.pos,
                           extern=True)
        ops: list[Op] = []
        stack: TypeStack = args.copy()
        verbose(f'start stack: {stack}')
        while (tok := self.lexer.next()).ttype != TokenType.End:
            try:
                op = self.parse_op(tok, stack)
            except TypeError as e:
                raise ParseError(tok.pos, str(e))
            ops.append(op)
        try:
            validate_stack(stack, rets, [])
        except TypeError as e:
            raise ParseError(
                tok.pos, 'invalid stack at the end of function',
                identifier.source, e)
        assert_ex(len(stack) == 0, ParseError(
            tok.pos, 'invalid stack at the end of function',
            identifier.source))
        return FuncDef(identifier.source, (args, rets), ops, func.pos)

    def include_file(self, path: str) -> bool:
        if os.path.exists(path):
            pass
        else:
            found = False
            for ip in self.include_path:
                if os.path.exists(expanded := os.path.join(ip, path)):
                    path = expanded
                    found = True
                    break
            if not found:
                return False
        if path in self.include_history:
            return True  # just skip without errors
        self.include_history.append(path)
        file = open(path)
        self.other_parser = Parser(
            Lexer(file), self.include_path, self.include_history)
        return True

    def next_tl(self) -> AstNode | None:
        """
        Next toplevel.
        only parses constructs that can occur in the toplevel of the
        translation unit
        """
        if self.other_parser:
            node = self.other_parser.next_tl()
            if node is None:
                # transfer all info to this scope
                self.funcs.update(self.other_parser.funcs)
                self.constants.update(self.other_parser.constants)
                self.include_history.extend(self.other_parser.include_history)
                self.other_parser = None
            else:
                return node
        try:
            tok = self.lexer.peek()
        except IndexError:
            return None
        if tok.ttype == TokenType.Const:
            constdef = self.next_const()
            self.constants[constdef.name] = constdef.value
            return constdef
        elif tok.ttype == TokenType.Func:
            funcdef = self.next_func()
            self.funcs[funcdef.name] = funcdef.signature
            return funcdef
        elif tok.ttype == TokenType.Include:
            self.lexer.next()  # consume the include token
            assert_ex(
                (path := self.lexer.next()).ttype == TokenType.String,
                ParseError(path.pos,
                           'expected include path after include keyword'))
            path = path.source.removeprefix('"').removesuffix('"')
            if not self.include_file(path):
                raise ParseError(tok.pos, f'could not find {path}')
            return self.next_tl()
        else:
            raise ParseError(tok.pos, f'unexpected token \'{tok.source}\'')


class CompilerBackend:
    asm: str = ''

    def compile_function(self, function: FuncDef):
        raise NotImplementedError(self.__class__.__name__)

    def pre_compile_function(self, name: str):
        raise NotImplementedError(self.__class__.__name__)

    def compile_from_parser(self, parser: Parser):
        while node := parser.next_tl():
            if isinstance(node, FuncDef) and not node.extern:
                self.pre_compile_function(node.name)
                self.compile_function(node)
                self.asm += '\n\n'

    def assemble(self) -> None:
        pass

    def finalize(self) -> str:
        try:
            self.assemble()
            return self.asm.strip()
        finally:
            del self  # not usable anymore so destroy self


class QbeBackend(CompilerBackend):
    types: dict[str, str] = {
        'int': 'w',
        'bool': 'w',
        'ptr': 'l',
        'long': 'l',
    }
    stack_bump: int = 0
    block_bump: int = 0
    strings: dict[str, str] = {}
    stack: list[tuple[str, str]] = []

    def pre_compile_function(self, name: str):
        self.stack_bump = 0
        self.block_bump = 0
        self.stack = []

    def ssa(self) -> str:
        self.stack_bump += 1
        return f'%s{self.stack_bump-1}'

    def block(self) -> str:
        self.block_bump += 1
        return f'@b{self.block_bump-1}'

    def inst(self, inst: str):
        self.asm += '    '+inst+'\n'

    def pop(self) -> tuple[str, str]:
        return self.stack.pop()

    def push(self, s: tuple[str, str]):
        self.stack.append(s)

    def compile_intrinsicop(self, op: IntrinsicOp):
        match op.intrinsic:
            case Intrinsic.Add | Intrinsic.Sub | Intrinsic.Mul | Intrinsic.Div:
                b, bt = self.pop()
                a, at = self.pop()
                c = self.ssa()
                assert_ex(bt == at, ParseError(
                    op.pos, f'mismatching types for {intrinsic2str(op.intrinsic)} operation'))
                inst = op.intrinsic.name.lower()
                self.inst(f'{c} ={self.types[bt]} {inst} {a}, {b}')
                self.push((c, bt))

            case Intrinsic.Lt | Intrinsic.Gt | Intrinsic.Lte | Intrinsic.Gte:
                b, bt = self.pop()
                a, at = self.pop()
                c = self.ssa()
                assert_ex(bt == at, ParseError(
                    op.pos, f'mismatching types for {intrinsic2str(op.intrinsic)} operation'))
                assert_ex(bt == 'int', ParseError(
                    op.pos, f'{intrinsic2str(op.intrinsic)} operation only supports int type'))
                is_signed = not bt.startswith('u')
                inst = 'c' + ('s' if is_signed else 'u') + {
                    Intrinsic.Lt: 'lt',
                    Intrinsic.Gt: 'gt',
                    Intrinsic.Lte: 'le',
                    Intrinsic.Gte: 'ge'
                }[op.intrinsic] + self.types[bt]
                self.inst(f'{c} ={self.types[bt]} {inst} {a}, {b}')
                self.push((c, 'bool'))

            case Intrinsic.Eq | Intrinsic.Neq:
                b, bt = self.pop()
                a, at = self.pop()
                c = self.ssa()
                assert_ex(bt == at, ParseError(
                    op.pos, f'mismatching types for {intrinsic2str(op.intrinsic)} operation'))
                inst = 'c'+{Intrinsic.Eq: 'eq',
                            Intrinsic.Neq: 'ne'}[op.intrinsic] + self.types[bt]
                self.inst(f'{c} ={self.types[bt]} {inst} {a}, {b}')
                self.push((c, 'bool'))

            case Intrinsic.BwAnd | Intrinsic.BwOr:
                b, bt = self.pop()
                a, at = self.pop()
                c = self.ssa()
                assert_ex(bt == at, ParseError(
                    op.pos, f'mismatching types for {intrinsic2str(op.intrinsic)} operation'))
                inst = {Intrinsic.BwAnd: 'and',
                        Intrinsic.BwOr: 'or'}[op.intrinsic]
                self.inst(f'{c} ={self.types[bt]} {inst} {a}, {b}')
                self.push((c, bt))

            case Intrinsic.Lsh | Intrinsic.Rsh:
                b, bt = self.pop()
                a, at = self.pop()
                c = self.ssa()
                assert_ex(bt in ['int'] and at == 'int', ParseError(
                    op.pos, f'mismatching types for {intrinsic2str(op.intrinsic)} operation'))
                inst = {Intrinsic.Lsh: 'shl',
                        Intrinsic.Rsh: 'shr'}[op.intrinsic]
                self.inst(f'{c} ={self.types[bt]} {inst} {b}, {a}')
                self.push((c, bt))

            case Intrinsic.Not:
                a, at = self.pop()
                b = self.ssa()
                assert_ex(
                    at in ['int', 'bool'],
                    ParseError(op.pos,
                               f'expected int or bool value for {intrinsic2str(op.intrinsic)} operation')
                )
                self.inst(f'{b} ={self.types[at]} ceq{self.types[at]} {a}, 0')
                self.push((b, at))

            case Intrinsic.Neg:
                a, at = self.pop()
                b = self.ssa()
                assert_ex(at.endswith('int'),
                          ParseError(op.loc, f'expected integer value for {intrinsic2str(op.intrinsic)}'))
                self.inst(f'{b} ={self.types[at]} neg {a}')
                self.push((b, at))

            case Intrinsic.Dup:
                self.push(self.stack[-1])

            case Intrinsic.Drop:
                self.pop()

            case Intrinsic.Swap:
                b = self.pop()
                a = self.pop()
                self.push(b)
                self.push(a)

            case Intrinsic.Rot:  # a b c -> b c a
                c = self.pop()
                b = self.pop()
                a = self.pop()
                self.push(b)
                self.push(c)
                self.push(a)

            case Intrinsic.Over:
                self.push(self.stack[-2])

            case Intrinsic.Int:
                self.stack[-1] = (self.stack[-1][0], 'int')

            case Intrinsic.Bool:
                self.stack[-1] = (self.stack[-1][0], 'bool')

            case Intrinsic.Ptr:
                self.stack[-1] = (self.stack[-1][0], 'ptr')

            case Intrinsic.Long:
                self.stack[-1] = (self.stack[-1][0], 'long')

            case Intrinsic.Str:
                self.stack[-1] = (self.stack[-1][0], 'ptr')

    def compile_conditional(self, op: Conditional):
        if_true_block = self.block()
        if_false_block = self.block()
        end_block = self.block()

        condition = self.pop()
        self.inst(f'jnz {condition[0]}, {if_true_block}, {if_false_block}')
        original_stack = self.stack.copy()

        self.asm += if_true_block+'\n'
        for operation in op.if_true:
            self.compile_op(operation)
        self.inst(f'jmp {end_block}')
        if_true_stack = self.stack

        self.stack = original_stack
        self.asm += if_false_block+'\n'
        for operation in op.if_false:
            self.compile_op(operation)
        self.inst(f'jmp {end_block}')
        if_false_stack = self.stack

        self.asm += end_block+'\n'
        for idx, (itr, ifa) in enumerate(zip(if_true_stack, if_false_stack)):
            if itr[0] != ifa[0]:
                result = self.ssa()
                self.inst(f'{result} ={self.types[itr[1]]} phi '
                          + f'{if_true_block} {itr[0]}, {if_false_block} {ifa[0]}')
                self.stack[idx] = (result, *self.stack[idx][1:])

    def compile_function_call(self, op: FunctionCall):
        args, rets = op.signature
        inst = ''
        inst += f'call ${op.name}('
        for idx, (argtype, sf) in enumerate(
                zip(args, reversed([self.pop() for i in args]))):
            if idx > 0:
                inst += ', '
            inst += self.types[argtype] + ' ' + str(sf[0])
            assert argtype == sf[1]
        inst += ')'
        if len(rets):
            result = self.ssa()
            inst = f'{result} ={self.types[rets[0]]} ' + inst
            self.push((result, rets[0]))
        self.inst(inst)

    def compile_str(self, op: PushStr):
        if op.value not in self.strings:
            self.strings[op.value] = f'$s{len(self.strings)}'
        self.push((self.strings[op.value], 'ptr'))

    def compile_op(self, op: Op):
        if isinstance(op, IntrinsicOp):
            self.compile_intrinsicop(op)
        elif isinstance(op, PushInt):
            self.push((op.value, 'int'))
        elif isinstance(op, PushStr):
            self.compile_str(op)
        elif isinstance(op, Conditional):
            self.compile_conditional(op)
        elif isinstance(op, FunctionCall):
            self.compile_function_call(op)
        else:
            assert False, "unreachable: unknown op: "+str(op)

    def compile_function(self, function: FuncDef):
        assert_ex(len(function.signature[1]) <= 1, ParseError(
            function.pos, 'C compatible function can have at most 1 return value.'))
        self.asm += 'export function '
        if len(function.signature[1]):
            self.asm += self.types[function.signature[1][0]]+' '
        self.asm += '$'+function.name.strip() + '('
        for idx, arg in enumerate(function.signature[0]):
            if idx > 0:
                self.asm += ', '
            name = self.ssa()
            self.push((name, arg))
            self.asm += self.types[arg] + ' ' + name
        self.asm += ') {\n'
        self.asm += self.block()+'\n'
        for op in function.body:
            self.compile_op(op)
        if len(function.signature[1]):
            self.inst(f'ret {self.pop()[0]}')
        else:
            self.inst('ret')
        self.asm += '}'

    def assemble(self) -> None:
        string_section = ''
        for s in self.strings:
            symbol = self.strings[s]
            string_section += 'data '+symbol+' = { b "'+s+'", b 0 }\n'
        self.asm = string_section + self.asm


def shift(argv: list[str]) -> tuple[str, list[str]]:
    return argv[0], argv[1:]


def print_help(prog: str):
    print(f'''Thijs' stack language compiler.
usage:
    {prog} [flags] <file>  - compiles the .tack file to a binary.
    {prog} -h|--help       - prints this help message.

flags:
    -o <file>              - writes the result to the specified file
    -cssa                  - compile to QBE's ssa ir
    -cs                    - compile to assembly
    -c                     - compile to object file
    -l <file>              - link with the given file. can be .o or .a
                             files. (only when compiling to binary)
    -nostdlib              - do not link with tack's standard library
    -I <path>              - look in this directory when searching for files
                             to include
    -v                     - dump debug information

to use the resulting .ssa file, qbe must be installed. use qbe to compile the
.ssa file to an assembly file which can be compiled using your standard C
compiler.''')


def parse_args() -> tuple[str, str, str, list[str], list[str]]:
    global VERBOSE
    argv = sys.argv.copy()
    prog, argv = shift(argv)

    output: str | None = None
    inputfile: str | None = None
    output_fmt: str | None = None
    link_list: list[str] = []
    include_path: list[str] = []
    need_stdlib: bool = True

    while len(argv) > 0:
        arg, argv = shift(argv)
        if arg in {'-h', '--help'}:
            print_help(prog)
            exit(0)
        elif arg == '-o':
            output, argv = shift(argv)
        elif arg == '-cssa':
            output_fmt = 'ssa'
        elif arg == '-cs':
            output_fmt = 's'
        elif arg == '-c':
            output_fmt = 'o'
        elif arg == '-l':
            file, argv = shift(argv)
            link_list.append(file)
        elif arg.startswith('-l'):
            link_list.append(arg.removeprefix('-l'))
        elif arg == '-nostdlib':
            need_stdlib = False
        elif arg == '-I':
            file, argv = shift(argv)
            include_path.append(file)
        elif arg.startswith('-I'):
            include_path.append(arg.removeprefix('-I'))
        elif arg == '-v':
            VERBOSE = True
        else:
            assert inputfile is None, 'too many source files given'
            inputfile = arg

    if inputfile is None:
        print_help(prog)
        exit(1)
    if output is None and output_fmt:
        output = inputfile.removesuffix('.tack')+'.'+output_fmt
    elif output is None:
        output = inputfile.removesuffix('.tack')

    stdlib = get_stdlib()
    if need_stdlib and stdlib not in link_list:
        link_list.append(stdlib)

    if need_stdlib:
        for path in get_include_path():
            if path not in include_path:
                include_path.append(path)

    return output, inputfile, output_fmt, link_list, include_path


def main():
    output, inputfile, output_fmt, link_list, include_path = parse_args()

    verbose('include path:\n-', '\n- '.join(include_path))
    verbose('link list:\n-', '\n- '.join(link_list))

    verbose('generating QBE IR')
    backend = QbeBackend()
    with open(inputfile) as rf:
        try:
            parser = Parser(Lexer(rf), include_path)
            backend.compile_from_parser(parser)
        except ParseError as e:
            raise e
            print(e)
            exit(1)
    ssa_form = backend.finalize()

    if output_fmt == 'ssa':
        verbose('writing', output)
        with open(output, 'w') as wf:
            wf.write(ssa_form)
    elif output_fmt == 's':
        verbose('cmd:', 'qbe', '-o', output)
        exit(subprocess.run(['qbe', '-o', output], stdout=subprocess.PIPE,
             input=ssa_form.encode()).returncode)
    else:
        verbose('cmd:', 'qbe')
        qbe = subprocess.Popen(
            ['qbe'],
            stdin=subprocess.PIPE,
            stdout=subprocess.PIPE
        )

        asm_form, stderr = qbe.communicate(ssa_form.encode())
        if qbe.returncode != 0:
            eprint('qbe:', stderr.decode())
        if output_fmt == 'o':
            ofile = output
        else:
            handle, ofile = tempfile.mkstemp('.o')
            verbose('created temp file', ofile)

        verbose('cmd:', 'as', '-o', ofile)
        gas = subprocess.Popen(
            ['as', '-o', ofile],
            stdin=subprocess.PIPE,
            stdout=subprocess.DEVNULL
        )

        _, stderr = gas.communicate(asm_form)
        if output_fmt == 'o':
            exit(gas.returncode)

        if gas.returncode != 0:
            eprint('as:', stderr.decode())
            exit(gas.returncode)

        verbose('cmd:', 'cc', '-o', output, ofile, *link_list)
        cc_code = subprocess.run(
            ['cc', '-o', output, ofile, *link_list]).returncode

        verbose('rm', ofile)
        os.remove(ofile)
        exit(cc_code)


if __name__ == '__main__':
    if DEBUG or VERBOSE:
        main()
    else:
        try:
            main()
        except Exception as e:
            eprint(e)
            exit(1)
